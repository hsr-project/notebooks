{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 画像認識による物体検出\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>この章の目的</b>\n",
    "    <p>画像処理で物体の座標を検出する方法を学習します</p>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップ作業"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なライブラリをインポートして、初期化を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import rospy\n",
    "import tf\n",
    "from utils import *\n",
    "rospy.init_node(\"recognition\")\n",
    "rgbd = RGBD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rvizを起動します．ロボットモデル、カメラ映像、ポイントクラウドが表示されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash --bg\n",
    "rviz -d data/5_recognition.rviz > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 認識対象の配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回、認識対象とするレゴブロックをHSRの前に出現させましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_object(\"e_lego_duplo\", 0.6, 0.0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レゴブロックが頭部カメラの画角に入るように頭を少し下げます。rviz上の頭部カメラの映像が変化することを確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 頭部を動かします\n",
    "# 下向きの場合は負、上向きの場合は正の値を引数に与えます\n",
    "move_head_tilt(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## センサ情報の取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はセンサ情報として、頭部RGB-Dカメラから取得できるポイントクラウド情報を利用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下でRGB-Dカメラから取得したRGB画像を表示することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を取得します\n",
    "image_data = rgbd.get_image()\n",
    "# 取得した画像を表示してみます\n",
    "plt.imshow(image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像データは、480x640x3の3次元配列です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最初の2次元は（y, x）のピクセルに対応します。最後の1次元はRGB形式のピクセル値です。\n",
    "\n",
    "例えば以下の命令で左上のピクセルのRGB値にアクセスできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ポイントクラウド情報には、各ピクセルの3次元座標値が格納されています。\n",
    "\n",
    "以下を実行することで、深度情報を表示することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ポイントクラウドを取得します\n",
    "points_data = rgbd.get_points()\n",
    "# ポイントクラウドの深度情報を表示してみます\n",
    "plt.imshow(points_data['z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度情報は、480x640の2次元配列です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_data['z'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像データと同様に、以下の命令で左上のピクセル値にアクセスできます。単位はメートルです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_data['z'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 色空間の変換と色抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レゴブロックの色は「水色」なので、色を使ってレゴブロックを検出してみましょう。\n",
    "\n",
    "「image_data」にはRGB形式で色のデータが格納されています。\n",
    "RGB形式のデータをそのまま使ってもよいのですが、RGBからHSVに色空間を変換すると照明変化に頑健になることが知られています。\n",
    "\n",
    "HSVは、色相(Hue)、彩度(Saturation)、明度(Value)によって色を表現します。今回は色相情報のみを利用してレゴブロックの水色を抽出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の色相の値を取得します\n",
    "h_image = rgbd.get_h_image()\n",
    "# 色相画像を表示してみます\n",
    "plt.imshow(h_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "色相画像に対して適当な閾値を設定して、レゴブロックのみが抽出されるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def f(lower = 0, upper = 255):\n",
    "    yellow_region = (h_image > lower) & (h_image < upper)\n",
    "    plt.imshow(yellow_region)\n",
    "\n",
    "interact(f, lower=(0, 255, 5), upper=(0, 255, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "閾値を下限130、上限140ぐらいに設定すると安定して抽出できるようです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>課題</b>\n",
    "    <p>同様にバナナやリンゴを抽出してみましょう。</p>\n",
    "    <p>以下を実行することで、バナナとリンゴを出現させることができます。</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_object(\"banana\", 0.6, 0.2, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_object(\"apple\", 1.0, 0.0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レゴブロックの位置の取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レゴブロックを抽出できる色相画像の閾値を設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd.set_h(130, 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定した閾値の色相画像を表示させてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = rgbd.get_region()\n",
    "plt.imshow(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ポイントクラウド情報から、レゴブロックと考えられる領域のxyz座標の平均値を計算します。\n",
    "\n",
    "レゴブロックのxyz座標が以下のように計算できました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd.get_xyz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このxyz値は、「head_rgbd_sensor_rgb_frame」基準座標、つまりRGBDカメラ座標上での値です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レゴブロックの座標の出力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力される座標の名前を`lego`にセットしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd.set_coordinate_name(\"lego\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新しいポイントクラウド情報が入力されるたびにbananaの座標情報が出力されます。\n",
    "\n",
    "「TF」の「Frames」から`lego`を選択してが正しくpublishされているか確認しましょう。\n",
    "\n",
    "![title](./imgs/5_lego_tf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "座標情報はPythonでもアクセスできます。\n",
    "\n",
    "例えば、絶対座標（map）上での`lego`の位置(x, y)は以下のように取得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = get_relative_coordinate(\"map\", \"lego\")\n",
    "x = trans.translation.x\n",
    "y = trans.translation.y\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lego`は、絶対座標上で約（x, y）=（0.6, 0.0）の座標に置かれているようです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 認識結果を用いた制御"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上の認識器を用いて、HSRにレゴブロックを拾わせてみましょう。\n",
    "\n",
    "前章の関数`move_wholebody_ik`に認識結果のx, yを引数として与え、逆運動学によってHSRを制御します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハンドを開く\n",
    "move_hand(1)\n",
    "# 逆運動学を使ってHSRの手先を動かします\n",
    "move_wholebody_ik(x, y, 0.1, 180, 0, 0)\n",
    "# ハンドを閉じる\n",
    "move_hand(0)\n",
    "# アームを初期姿勢に戻す\n",
    "move_arm_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>課題</b>\n",
    "    <p>レゴブロックを出現させる位置を変えても上手く拾えるか試してみましょう。</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レゴブロックを削除\n",
    "delete_object(\"e_lego_duplo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レゴブロックを配置\n",
    "put_object(\"e_lego_duplo\", 0.6, 0.2, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自分で考えてみましょう。この下に入力できます。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
